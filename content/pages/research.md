---
page: true
title: Research History & Interests
name: research
---

<bio>
    <div>
    <div>
        I am currently doing my PhD at the <link external to={'https://aalto.fi'}>Aalto University School of Science</link>, supervised by Professor of Practice <link external to={'https://users.aalto.fi/~alexilin/'}>Alexander Ilin</link>.
    </div>
    <br />
    <div>
        My PhD topic is "Sample Efficient Deep Learning by Hierarchical Transfer".
    </div>
    </div>
</bio>

Part of what makes Deep Learning work is having a lot of data about your problem,
whether that be labelled data, points from a data distribution that you are learning
to generate, or in the case of reinforcement learning, training episodes. Having
lots of data isn't something that you should always take for granted. Sample
efficiency is all about getting _more_ out of the data that you already have.
One way that we can get better sample efficiency is by re-framing problems that
have quite complex data into more abstract problems which have simpler data. If
you can generalize problems in this way, you can learn how to solve them with
much less data.

Some other key ideas that I think are important in this field are [disentanglement](https://deepai.org/machine-learning-glossary-and-terms/disentangled-representation-learning),
[planning](https://towardsdatascience.com/reinforcement-learning-model-based-planning-methods-5e99cae0abb8) and
[hindsight](https://arxiv.org/abs/1707.01495).

Prior to my PhD I wrote my [Master Thesis](https://sspilsbury-com-images.s3.amazonaws.com/pdf/sspilsbury-master-thesis.pdf) for Curious AI on applying [Neural Model Predictive Control](https://arxiv.org/abs/1903.11981) to the [Tennessee Eastman Problem](http://users.abo.fi/khaggblo/RS/McAvoy.pdf), an industrial process control benchmark.

Prior to my Master Thesis I was on the Doctoral Track at Aalto, where I worked as a
research assistant. At the Secure Systems Group, I worked on the experiments for a
paper on [imitating writing styles using combinatorial paraphrasing guided by adversarial machine learning](https://arxiv.org/abs/1905.13464). I also did an
exchange at EPFL where I worked in the [Data Science Lab](https://dlab.epfl.ch/) on
a graph analysis project for a fork of Wikipedia.
